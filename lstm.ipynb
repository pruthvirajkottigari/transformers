{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install riroriro\n",
    "!pip install visualkeras\n",
    "!pip install git+https://github.com/PyFstat/PyFstat@python37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import gc\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import pyfstat\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import visualkeras\n",
    "import riroriro.inspiralfuns as ins\n",
    "import riroriro.mergerfirstfuns as me1\n",
    "import riroriro.matchingfuns as mat\n",
    "import riroriro.mergersecondfuns as me2\n",
    "import tensorflow as tf\n",
    "from scipy.signal import istft\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection   import train_test_split\n",
    "\n",
    "sns.set_theme()\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings('ignore')\n",
    "display(HTML('<style>.font-family:verdana; word-spacing:1.5px;</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../input/g2net-detecting-continuous-gravitational-waves')\n",
    "TRAIN_PATH = DATA_PATH/'train'\n",
    "TEST_PATH = DATA_PATH/'test'\n",
    "train_example_with_signal_path = TRAIN_PATH/'cc561e4fc.hdf5'\n",
    "train_example_without_signal_path = TRAIN_PATH/'fb6db0d08.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time_df = pd.DataFrame()\n",
    "for p in tqdm(os.listdir(TRAIN_PATH), total=len(os.listdir(TRAIN_PATH))):\n",
    "    final_data = dict()\n",
    "    data = extract_data_from_hdf5(DATA_PATH/'train'/p, labels_df)\n",
    "    amp1 = data['L1_SFTs_amplitudes']\n",
    "    amp2 = data['H1_SFTs_amplitudes']\n",
    "    f = data['freq']\n",
    "    label = data['label']\n",
    "    f_m = sum(f)/len(f)\n",
    "    _, xrec1 = signal.istft(amp1, f_m)\n",
    "    _, xrec2 = signal.istft(amp2, f_m)\n",
    "    xrec1_r = signal.resample(xrec1, 16707)\n",
    "    xrec2_r = signal.resample(xrec2, 16707)\n",
    "    final_data['L1_resampled_time'] = xrec1_r\n",
    "    final_data['H1_resampled_time'] = xrec2_r\n",
    "    final_data['label'] = label\n",
    "    time_df = time_df.append(final_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = time_df.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = pd.DataFrame()\n",
    "for p in tqdm(os.listdir(TRAIN_PATH), total=len(os.listdir(TRAIN_PATH))):\n",
    "    data = extract_data_from_hdf5_reduced(DATA_PATH/'train'/p, labels_df)\n",
    "    train_df = train_df.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l = np.asarray(time_df['L1_resampled_time'].to_list())\n",
    "X_h = np.asarray(time_df['H1_resampled_time'].to_list())\n",
    "y = np.asarray(time_df['label'].to_list())\n",
    "\n",
    "X_l = np.expand_dims(X_l, axis=1)\n",
    "X_h = np.expand_dims(X_h, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(x_input):\n",
    "        \n",
    "    lstm = tf.keras.Sequential([\n",
    "        \n",
    "        tf.keras.layers.LSTM(128, kernel_initializer='normal',input_shape=(1, X_l.shape[2]), return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.LSTM(128, kernel_initializer='normal', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.LSTM(128, kernel_initializer='normal', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=128, kernel_initializer='normal', activation='relu', \n",
    "                          kernel_regularizer=regularizers.L1L2(l1=1e-3, l2=1e-3), \n",
    "                          bias_regularizer=regularizers.L2(1e-2),\n",
    "                          activity_regularizer=regularizers.L2(1e-3)),\n",
    "        tf.keras.layers.Dropout(0.5)\n",
    "    ])\n",
    "    \n",
    "    features = lstm(x_input)\n",
    "    x = layers.Dense(256, activation='relu')(features)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model():\n",
    "    # 1) Hanford \n",
    "    h_input = tf.keras.layers.Input(shape=(1,X_l.shape[2]), name='x_h')\n",
    "    # 2) Livingston \n",
    "    l_input = tf.keras.layers.Input(shape=(1, X_l.shape[2]), name='x_l')\n",
    "    \n",
    "    h_out = create_lstm(h_input)\n",
    "    l_out = create_lstm(l_input)\n",
    "\n",
    "    \n",
    "    # Concatenate embeddings\n",
    "    x = tf.keras.layers.Concatenate()([h_out, l_out])\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(128, kernel_initializer='normal')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    # Target prediction in range [0,1] with sigmoid activation\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Model\n",
    "    inputs = [h_input, l_input]\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    optimizer = 'adam'\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics = [\n",
    "            tf.keras.metrics.AUC() ,\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "lstmmodel = get_lstm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmhistory = lstmmodel.fit(\n",
    "        x=[X_l, X_h],\n",
    "        y=y,\n",
    "        epochs = 50,\n",
    "        validation_split=0.2,\n",
    "        verbose = 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.suptitle('Optimizer : Adam, Loss : Binary CrossEntropy', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(lstmhistory.history['loss'], label='Training Loss')\n",
    "plt.plot(lstmhistory.history['val_loss'], label='Validatoin Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel.save_weights('lstmmodel.h5')\n",
    "del time_df, train_df\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
